{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d2223-4f69-4e49-8ebe-4e20c6b0d295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44a0edac-deaa-41b4-9814-10172d6bf3fa",
   "metadata": {},
   "source": [
    "## TITANIC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb6f389-2688-437d-b1ae-35c7fac20a0c",
   "metadata": {},
   "source": [
    "# 1. Introduction et Contexte"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d15d7-d981-4fcb-903f-6734159dc725",
   "metadata": {},
   "source": [
    "Dans ce projet, nous nous attaquons à la compétition Titanic - Machine Learning from Disaster sur Kaggle. L'objectif principal est de prédire si un passager a survécu ou non au naufrage du Titanic en fonction de certaines caractéristiques des passagers (comme l'âge, le sexe, la classe, etc.). Le but est d'appliquer des techniques de machine learning pour construire un modèle prédictif performant.\n",
    "\n",
    "Le cadre d'analyse se situe dans le contexte de l'apprentissage supervisé, où les données d'entraînement sont utilisées pour prédire la variable cible Survived (0 pour la survie, 1 pour la non-survie)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c61f3-6faa-42a4-933a-4dec95cc977c",
   "metadata": {},
   "source": [
    "# 2. Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b0e6d-2f7c-4c78-974c-c8588127bede",
   "metadata": {},
   "source": [
    "Exploration des données initiales\n",
    "Les données initiales sont fournies sous forme de fichiers CSV :\n",
    "\n",
    "train.csv : contient les données d'entraînement (caractéristiques des passagers et le résultat de leur survie).\n",
    "test.csv : contient les caractéristiques des passagers, mais sans la variable cible.\n",
    "gender_submission.csv : fournit un exemple de format de soumission pour Kaggle.\n",
    "Changement de type de colonnes\n",
    "Nous devons nous assurer que les types des colonnes sont corrects pour une analyse efficace. Par exemple, nous devons nous assurer que la colonne Age est de type numérique et que Survived est une variable binaire.\n",
    "\n",
    "Traitement des valeurs manquantes\n",
    "Certaines colonnes, comme Age ou Fare, peuvent contenir des valeurs manquantes. Nous devons les traiter, soit par suppression, soit en les remplissant avec des valeurs comme la médiane ou la moyenne.\n",
    "\n",
    "Modification et création de nouvelles variables\n",
    "Nous pouvons créer de nouvelles variables pour enrichir le modèle. Par exemple :\n",
    "\n",
    "Créer une variable qui indique si le passager est un enfant ou un adulte.\n",
    "Transformer les variables catégorielles en variables numériques (par exemple, Sex -> 0 pour \"male\" et 1 pour \"female\").\n",
    "Normalisation ou transformation des données\n",
    "Certaines variables numériques, comme Fare, peuvent être normalisées pour être comprises dans une échelle similaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4237a425-7bc8-45cc-bafb-a49662186cf3",
   "metadata": {},
   "source": [
    "# 3. Exploration des données (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549cbf9e-74b4-4e9d-8351-f8dd142cd6a1",
   "metadata": {},
   "source": [
    "Visualisation des données\n",
    "La visualisation est essentielle pour comprendre la distribution des variables et les relations entre elles. Utilisez des histogrammes pour les distributions, des diagrammes en boîte pour détecter les valeurs aberrantes, et des graphiques de dispersion pour explorer les relations entre les variables.\n",
    "\n",
    "Analyse statistique descriptive\n",
    "Calculez des statistiques de base, comme la moyenne, la médiane, l'écart-type, et analysez les valeurs extrêmes (outliers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5163f3-1862-482b-8319-de66f03bf6ae",
   "metadata": {},
   "source": [
    "# 4. Analyse de la Corrélation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92099921-d371-4025-97e5-b7404b80e428",
   "metadata": {},
   "source": [
    "Calcul de la corrélation entre les variables\n",
    "Une matrice de corrélation vous aidera à comprendre comment les variables sont liées les unes aux autres et à la variable cible.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "corr_matrix = train_data.corr()\n",
    "print(corr_matrix)\n",
    "Visualisation de la matrice de corrélation\n",
    "Une carte thermique (heatmap) de la matrice de corrélation permet de mieux visualiser ces relations.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()\n",
    "5. Préparation finale des données\n",
    "Séparation des données d’entraînement et de test\n",
    "Avant de construire le modèle, nous devons séparer les données en deux ensembles : un ensemble pour l'entraînement et un autre pour les tests.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_data.drop(['Survived'], axis=1)  # Variables explicatives\n",
    "y = train_data['Survived']  # Variable cible\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "Création des variables cible et explicatives\n",
    "Les variables explicatives sont toutes les colonnes sauf Survived, tandis que la variable cible est Survived."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5be12-c20b-48e4-835d-9e150a8e141c",
   "metadata": {},
   "source": [
    "# 6. Modélisation et Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbca514-0eb0-4237-a64a-84804513e0e2",
   "metadata": {},
   "source": [
    "Choix et entraînement des modèles\n",
    "On peut tester plusieurs modèles de machine learning pour prédire la survie des passagers. Un bon point de départ serait d'utiliser un modèle de régression logistique ou un forêt aléatoire.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "Évaluation des performances\n",
    "Une fois le modèle entraîné, il faut évaluer sa performance en utilisant la précision, la rappel, et la F1-score.\n",
    "\n",
    "python\n",
    "Copy\n",
    "Edit\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308866f6-a8d9-4e65-bea0-02f041021955",
   "metadata": {},
   "source": [
    "# 7. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962ab2a-0350-4873-82dd-64519c490560",
   "metadata": {},
   "source": [
    "Synthèse des résultats et des observations\n",
    "Le modèle choisi a montré une précision de 0.7989, ce qui est un bon point de départ pour cette compétition.\n",
    "En fonction des résultats, vous pouvez explorer d'autres modèles, comme le Gradient Boosting ou le XGBoost, ou même ajuster les hyperparamètres du modèle choisi pour améliorer les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e664ef-10af-4552-9868-58370f120fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90ac3aa2-a879-465a-b93d-658845cbf0af",
   "metadata": {},
   "source": [
    "## CODE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd4c4b9d-3ecf-42d6-a4ed-e22036f2efce",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/titanic/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Charger les données depuis les chemins Kaggle\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/titanic/train.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m test_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/titanic/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m gender_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/titanic/gender_submission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/titanic/train.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger les données depuis les chemins Kaggle\n",
    "train_data = pd.read_csv(train.csv')\n",
    "test_data = pd.read_csv(test.csv')\n",
    "gender_submission = pd.read_csv('/kaggle/input/titgender_submission.csv')\n",
    "\n",
    "# Prétraitement des données d'entraînement\n",
    "train_data = train_data[['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "train_data['Age'] = train_data['Age'].fillna(train_data['Age'].median())\n",
    "train_data['Fare'] = train_data['Fare'].fillna(train_data['Fare'].median())\n",
    "\n",
    "# Convertir la variable catégorielle 'Sex' en numérique\n",
    "train_data['Sex'] = train_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# Séparer les caractéristiques et la cible\n",
    "X = train_data.drop('Survived', axis=1)\n",
    "y = train_data['Survived']\n",
    "\n",
    "# Diviser les données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Entraînement du modèle\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Évaluation du modèle\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Prétraitement des données de test\n",
    "test_data = test_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "test_data['Age'] = test_data['Age'].fillna(test_data['Age'].median())\n",
    "test_data['Fare'] = test_data['Fare'].fillna(test_data['Fare'].median())\n",
    "test_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "X_test_data = scaler.transform(test_data)\n",
    "\n",
    "# Vérifier la colonne PassengerId dans test_data\n",
    "if 'PassengerId' not in test_data.columns:\n",
    "    test_data['PassengerId'] = range(1, len(test_data) + 1)  # Si la colonne PassengerId manque, on la recrée\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "predictions = model.predict(X_test_data)\n",
    "\n",
    "# Sauvegarder les prédictions dans un fichier de soumission\n",
    "submission = pd.DataFrame({\n",
    "    'PassengerId': test_data['PassengerId'],\n",
    "    'Survived': predictions\n",
    "})\n",
    "\n",
    "# Sauvegarder le fichier de soumission sous 'submission.csv'\n",
    "submission.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "\n",
    "print(\"Submission file has been saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1604cda-6486-4ea9-85d0-f37b5f9bca21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff6fbb-15a3-4ee2-8112-f2ff26850a66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a298dae-06aa-4050-8e3c-2859f684efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c041c04-fb5f-4583-a2a8-59826c813f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c4da7-7421-44db-b075-d402307737fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
